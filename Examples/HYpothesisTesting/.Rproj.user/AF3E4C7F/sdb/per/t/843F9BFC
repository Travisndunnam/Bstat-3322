{
    "contents" : "---\ntitle: \"Hypothesis Testing using Randomization Distributions\"\nauthor: \"by Craig W. Slinkman\"\ndate: \"October 22, 2015\"\noutput: word_document\n---\n```{r,Prologm,echo=FALSE}\nECHO <- TRUE\n\n```\n\n\n#Q1: \nA certain chemical pollutant in the Genesee River has been constant for several years with mean Î¼ = 34 ppm (parts per million). A group of factory representatives whose companies discharge liquids into the river is now claiming that they have lowered the average with improved filtration devices. A group of environmentalists will test to see if this is true at the 5% level of significance. They have drawn a random sample of size 25 from the river.  The sample values are given below in the vector $PPM$.  \n\n```{r, Q1.0,echo=FALSE}\nset.seed( 11235 )\nPPM <- round( rnorm( 25 , 32, 9 ))\nPPM\n```\n\n## The null hypothesis and alternative hypothesis\nThe environment group wants to test the claim that the level of the pollutant is lower than 34 ppm.  So are null and alternative hypothesis are: $$NH: \\mu=34$$\n$$AH: \\mu<34$$\n\n \nPerform a hypothesis test at the 5% level of significance and state your decision. \n\n## Graphics and descriptive statistics\nThe first set in statistical analysis is to draw a suitable graphic.  When analyzing quantitative data with the small sample sizes the dotplot is the ideal graphic. \n\n```{r Q1.1}\nrequire( ggplot2 )\n\nggplot( data.frame( PPM ),\n        aes( x=PPM )) +\n    geom_dotplot( binwidth = 1 ) +\n    xlab( \"Pollutant (PPM)\" ) +\n    ylab( \"Count\" ) +\n    ggtitle( \"Genesee River Pollutant Measurements\")\n    \n ybar <- round( mean(PPM), 1) \n s    <- round( sd( PPM ), 1)\n\n```\n\n$$\\bar{y}=`r ybar`$$\n$$s=`r s`$$\n\n## Creating the randomization distribution for the hypothesis test\nWe must adjust the sample data so that it centered on the null hypothesis value.  We do this by subtracting the sample mean from each sample value and then adding the null hypothesis value to each observation. \n\nIn R we do this as follows.  \n\n```{r Q1.2,echo=TRUE}\n \nadjusted <- PPM - ybar + 34    # Adjust sample mean to NH value.\nadjusted\ncat( \"mean(Adjusted)=\",        # For clearer output.\n     round(mean(adjusted),1 ))\n```\n  \n We now compute the randomization distribution of the adjusted values.  We will use 5,000 replications because this is an important issue.  \n \n \n \n```{r Q1.3,echo=TRUE}\n###########################################################\n# We must load the simpleboot package for bootstrap      #\n# functionality.                                          #\n###########################################################\n\nrequire( simpleboot )                 \n#\n#\n###########################################################\n# Because of the importance of the decision we use choose  #\n# to use 5,000 replications.                             #\n###########################################################\n#\nreps <- 5000                          \n#\n#\n##########################################################\n# We compute 5,000 bootstrap samples of the data that    #\n# was adjusted to make the null hypothesis true for the  #\n# adjusted data.                                         #\n##########################################################\n#\nbootOut <- one.boot( adjusted,        \n                     mean,\n                     reps )\n#\n#\n##########################################################\n# We extract the bootstrap sampling distribution from    #              \n# bootOut list.                                          #\n##########################################################\n#\nbsd <- bootOut$t     # Bootstrap sampling distribution                      \n#\n#'\n##########################################################\n# We compute the usual bootstrap diagnostics:            #\n#                                                        #\n# 1. Bootstrap sampling mean which should be             #\n#   approximately equal to the NH value.                 #\n#                                                        #\n# 2. We also plot the bootstrap sampling distribution    #\n#    along with the plotted sample statistic to give us  #\n#    a visual interpretation of the pVlaue.              #\n##########################################################\n#\nbsMean <- round( mean( bsd ) )     # Bootstrap sampling \n                                   # mean \n\n```\n\n\n# Computing the p-value\nBecause we have a lower tail hypothesis we compute the proportion of observations whose value is less that the $$\\bar{y} and divide this number by the number of replications $reps$.  We do this below:  \n\n```{r,Q1.4,echo=TRUE}\n\nlowerTail <- adjusted[ bsd < ybar ]\npValue <- round( length( lowerTail ) / reps, 4 )\nxx <- round( 10000 * pValue )\n\n```\n\nThe p-value for the null hypothesis is `r pValue`. \n\n## Statistical conclusion\nThis is evidence that the null hypothesis is incorrect.  \n\n*At the 5% or 0.05 level of significance we would reject the null hypothesis.  \n\n*There is insufficient evidence to reject the null hypothesis as the 0.01 or 1% level of significance.  \n\n## Managerial conclusion\nThere is some evidence that the pollution level has been reduced.  At the scientific standard of the 5% level of significance there is evidence that the pollution level has been decreased.\n\n# Corporate health care\nThe Human Resources Department of a large corporation wanted to determine if a majority of its employees were satisfied with their treatment by the corporation's health care provider. A random sample of 400 employees was selected, and 275 indicated that they were satisfied with their treatment. Does this data show at the 2% level of significance that a majority of all employees is satisfied? Suppose that the Corporation's president required that more than 60% of employees should be satisfied. Does this data support that requirement at the 2% level of significance? \n\n## The null and alternative hypothesis\nWe want to show that the proportion of employees that are satisfied with the corporate health care provider is greater than 60% which is a proportion of 0,60.  Hence our null and alternative hypothesis are  \n\n\\newpage\n\n$$NH: p=0.60$$\n$$AH: p>0.60$$\n\n## Synthetic sample\nWe are not given the original sample data but summarized data.  We know that\n263 employees are satisfied with the provider and that `r 500-263` are not satisfied.  We use these figures to construct our synthetic sample which I will call $survey$:\n\n```{r Q2.1,echo=TRUE}\n\nrm( list=ls() )\nn <- 500\ns <- 323\nf <- n - s\n\nsurvey <- c( rep( 1, s ),\n             rep( 0, f ))\ntable(survey)\n\nphat <- round( sum(survey)/ n, 3 )\n\n```\n\n## Computing the point estimate $\\hat{p}$\n  \n```{r, Q2.15,echo=TRUE}\n\nphat <- round( s / n )\n\n```\n\nThe point estimate for the proportion is computed as follows\n    $$\\hat{p}=\\frac{x}{n}=`r phat`$$\n    \n## Adjusting the sample data to make the null hypothesis true\nWe assume that the null hypothesis is true. For proportions we can do this theoretically because under the null hypothesis 60% of the sample sizes should be true and 40% should be false.  Therefore we have\n\n```{r Q2.2,echo=TRUE}\n\ntrueNH <- c( rep( 1, 300 ),\n\n                          rep( 0, 200 ))\ntable(trueNH)\n```\n\n## Compute the randomization distribution\nBecause we are using random sample data we can create the bootstrap sampling distribution the true NH synthetic sample.\n```{r Q2.3,echo=TRUE}\n\nset.seed( 111 )          # For reproducibility.\n\nrequire( simpleboot )    # Load simpleboot package.\n\nreps <- 10000\n\nbootOut <- \n    one.boot( trueNH,\n              mean,\n              reps )\n\nbsd <- bootOut$t\n\nggplot( data.frame( bsd ),\n        aes(x=bsd)) +\n    geom_histogram(  binwidth=0.005,\n                      color='blue',\n                      fill='yellow') +\n    geom_segment( x=phat, y=0,\n                  xend = phat, yend=1100) +\n    xlab( expression( hat(p) )) +\n    ylab( \"Frequency \") +\n    ggtitle( \"Bootstrap sampling destruction of Null True Hypothesis\" )\n\n```\n\n## Computing the p-value\nThe alternative hypothesis is an upper-tail hypothesis.  Therefore we count all the randomization distribution values and divide the replications.  \n\n```{r Q2.4,echo=TRUE}\ncount <- length( bsd[bsd>phat] )\npValue <- round( count / reps, 4 ) \n\n```\n  \n $$pValue=`r pValue`$$\n \n## Statistical conclusion\n Because the p-value=`r pValue` is less than 0.02000 there is sufficient evidence to conclude that the null hypothesis is unlikely and we reject it.\n \n## Managerial conclusion\nThere is sufficient evidence to conclude that the percentage of employees who are satisfied with the healthcare plan exceeds 60%.   \n\n# 3: Commute Atlanta: Is there a difference mean commute time driving home between genders\nWe want determine if there is a difference between the mean commute times in Atlanta for different genders.  \n\n## The data\nThe data can be accessed in the R-package $LOck5Data$ in the $CommuteAtlanta$ data frame.  We need to divide the data into two subsamples based on the sex driver.  We are only interest in the variable $Time$ which is the $4^{th}$ variable in the dataset.  \n\n## The hypothesis set\nWe define the following symbols  \n\nParameter | Interpretation  \n----------|---------------  \n$\\mu_M$   | Male mean commute time  \n$\\mu_F$   Female mean commute time  \n\nWe can formulate out hypotheses as follows:  \n$$NH: \\mu_M = \\mu_F$$\n$$AH: \\mu_M \\ne \\mu_F$$ \n\nA more useful but equivalent formulation of our hypothesis set is \n\n$$NH: \\mu_M - \\mu_F = 0$$\n$$AH: \\mu_M - \\mu_F = 0$$ \n\n## The data set \n\nThe dataset can be found in the R-package $Lock5Data.  The data frame name is $CommuteAtlanta$.  We need to create two subsamples based on gender.  We are only interested in the compute time variable $Time$.  \n\nThe chunk below shows how to the carry out these tasks.\n\n```{r, Q3.0,echo=TRUE}\nrm(list=ls())\nset.seed( 14925 )\n\nrequire( Lock5Data )\ndata( CommuteAtlanta )\nhead( CommuteAtlanta )\n\nMales   <- CommuteAtlanta[CommuteAtlanta$Sex==\"M\",4]\nFemales <- CommuteAtlanta[CommuteAtlanta$Sex==\"F\",4]\n\n```\n\n## Graphical and descriptive statistics\nWe should always plot the data when it is quantitative.  Because we are comparing multiple sub-populations we use comparative boxplots.  Note that we need the original data frame $CommuteAtlanta$ to plot this data.\n\n```{r Q3.1,echo=TRUE}\nrequire( ggplot2 )\n \nggplot( CommuteAtlanta,\n        aes( x=Sex, y=Time)) +\n    geom_boxplot() +\n    xlab( \"Gender\" ) +\n    ylab( \"Time in minutes\" ) +\n    ggtitle( \"Commute Atlanta \\n Commute time by gender\")\n\nbarM     <- round( mean( Males), 1 )\nbarF     <- round( mean( Females ), 1 )\nbarDif  <- barM - barF    \n\n```\nWe have the following sample statistics:\n\n$$\\bar{y}_M = `r barM`$$\n$$\\bar{y}_F =`r barF`$$\n$$\\bar{y}-\\bar{y}_F = `r barDif`$$\n\n## Adjusting the sample data to make the null hypothesis true\nWe the null hypothesis value is zero to adjust the sample to make the null hypothesis true all we need to do is to subtract the means of each sub-sample:\n\n```{r Q3.2, echo=TRUE}\n\nadjM <- Males - barM\nadjF <- Females - barF\nround (mean( adjM ), 1 )\nround( mean( adjF ), 1 )\n\n```\n\n\n## Creating the randomized distribution\nBecause we have two populations we must use the R-function $two.boot$ in the  $simpleboot$ package.\n\n```{r Q3.3,echo=TRUE}\n  \nrequire( simpleboot )\n\nbootOut <- two.boot( adjM, \n                     adjF,\n                     mean,\n                     5000 )\nrd <- bootOut$t\n\nggplot( data.frame( rd ),\n        aes( x = rd )) +\n    geom_histogram( binwidth=0.5,\n                    color=\"blue\",\n                    fill=\"yellow\") +\n    xlab( expression(bar(y)[M]-bar(y)[F]) ) +\n    ylab( \"Frequency\" ) +\n    ggtitle( expression( paste(\"Bootstrap sampling distribution of \", \n                        bar(y)[M]-bar(y)[F]) ))\n    \n```\n\n## Compute the p-value using the sample statistic\nThe computation of the p-value is more complex in two tail tests than in single tail tests.  We must include areas from both tails.  If the sampling distribution is symmetric we can approximate the p-value by multiply in the p-value as if we had a one-tail by two in the tail that test statistic is found.\n\n```{r !3.4,echo=TRUE}\ncount <- length( rd[rd>=barDif])\npValue <- round( 2 * count/5000, 4 )\n\n```\n\n$$p-value=`r pValue`$$\n\n## Statistical conclusion\nThe p-value of `r pValue` is less than 0.05 so we should reject the sample data is inconsistent with the null hypothesis.\n\n## Managerial Conclusion\nThere is mildly strong evidence that the null hypothesis that the mean commute time is the same for both males and females is incorrect.\n\n# Two sample proportions\nThe HuffPost Pollster (http://elections.huffingtonpost.com/pollster/2016-iowa-presidential-republican-primary) gives the following numbers for the Iowa Presidential Caucus.  \n```{r Q4.0,echo=TRUE}\nn <-401                  #Sample size\nnCarson <- 84            # Favor Carson\nnTrump  <- 59            # Favor Trump\n#\npCarson  <-  nCarson / n\n\npTrump <-  nTrump / n              \n\npDif <- pCarson - pTrump\n\n\n```\n\n\nCandidate     | Count | Proportion \n--------------|-------|------------  \nCarson        | `r nCarson` | `r round( pCarson, 3 )`  \nTrump         | `r nTrump`  | `r round( pTrump, 3 )` \n\n\nIs there sufficient evidence at the 5% level of significance that Carson will finish ahead of trump provided the caucus follows the opinion polls?\n\n## The Hypothesis set  \n\nLet $p_C$ be the proportion of votes who favor Carson and $p_T$ be the proportion of voters who favor Trump.  Our hypothesis set is as follows:  \n\n$$NH: p_C - p_T = 0$$\n$$AH: p_C - P_T > 0 $$  \n\n## The point estimate  \nThe point estimate of the difference in proportion is\n$$ \\hat{p}_C -  \\hat{p}_T =`r round( pDif, 3)`$$\n\n## Creating the boot sampling distribution\nBecause out results are from a random sample and not an experiment we can use the bootstrap sampling distribution.  We will use 10,000 replications and the $simpleboot$$ package function $$two.boot$ to create the bootstrap distribution.  \n\nAs before we will need to center the bootstrap distribution so that difference in proportion is equal to zero.  One way to do this is two create sampling at the mean proportion for both samples.  We compute this sampling distribution below.  \n\n```{r= Q4.2,echo=TRUE}\nCarson <- c ( rep( 1, nCarson ), rep( 0, n - nCarson ) )\nadjCarson <- Carson - pCarson\n\n\n\nTrump    <- c(  rep( 1, nTrump),   rep(0, n-nTrump))\nadjTrump <- Trump - pTrump\n\nreps <- 10000\nrequire( simpleboot )\n\nbootOut <- two.boot( adjCarson,\n                     adjTrump,\n                     mean,\n                     reps )\n\nbsd <- bootOut$t\n\n```\n  \nWe compute the mean of the bootstrap sampling distribution.  This value should be approximately equal to zero.  We also should plot the sampling distribution which we hope will v=be symmetric and mound shaped.  \n\n```{r Q4.4,echo=TRUE}\nbsdMean <- round( mean( bsd ), 3 )\n\nrequire( ggplot2 )\n\nggplot( data.frame( bsd ),\n        aes(x=bsd )) +\n    geom_histogram( binwidth=0.01,\n                    color=\"blue\",\n                    fill=\"yellow\") +\n    xlab( expression( hat(p)[C] - hat(p)[T]) ) +\n    ylab( \"Frequency\" ) +\n    ggtitle( expression(\n        paste( \"Reference distribution of NH:\",\n               p[C] - p[T]==0)))\n\n```\nThe mean of the reference distribution is equal to 0 to 3 decimal places. The reference distribution looks fairly symmetric and mound shaped.  Therefore we can proceed with computing the p-value.  \n\n## Computing the p-value\nThe alternative hypothesis specifies upper tail test.  We therefore we compute the p-value:  \n\n```{r Q4.5,echo=TRUE}\n\npValue <- round( ( length( bsd[ bsd >= pDif] )/ reps), 4)\n\n```\n\nThe p-values is `r pValue`.  \n\n## Statistical conclusion\nBecause the p-value=`r pValue` is less than 0.0500.  There is relatively strong evidence to reject the null hypothesis that Carson and Trump are tied.  \n\n## Subject matter conclusion\nThere is relatively strong evidence that Mr. Carson will win the Iowa Caucus if the Caucus is held on the same day as the survey.  \n\n# Cocaine addiction\nIn the statistical theory of design of experiments, randomization involves randomly allocating the experimental units across the treatment groups. For example, if an experiment compares a new drug against a standard drug, then the patients should be allocated to either the new drug or to the standard drug control using randomization.  \n\nWe are going to analyze two analyze the following healthcare problem:\n\n> In a randomized experiment on treating cocaine addiction, 48 people were randomly assigned to take either Desipramine (a new drug), or Lithium (an existing drug), and then followed to see who relapsed\n\nThe research question of interest: Is Desipramine better than Lithium at treating cocaine addiction?\n\nWe will use the following notation for the experiment:\n\n$pD=$the proportion of individuals receiving Desipramine who did not relapse  \n\n$pL=$the proportion of individuals receiving lithium who did not relapse.  \n\n\nThe sample data is in the R-package $Lock5Data$.  The data frame name is named $CocaineTreatment$.  The data is given below.\n\n\n\n```{r echo=TRUE}\n\nrm( list=ls())\nrequire( Lock5Data )\ndata(\"CocaineTreatment\")\nCT <- CocaineTreatment\nhead(CT)\ntail(CT)\n\n```\n\nWe need to compute the proportion of individuals who relapsed.  We will do this as follows: \n\n```{r Q5.1,echo=TRUE}\n\noutcome <- table( CT )\noutcome\n\npD <- outcome[1,1] / 24\npL <- outcome[2,1] / 24\npDif <- pD - pL\n\n```\n  \nThe point estimator of the difference in proportions is \n$$\\hat{p}_D - \\hat{p}_L=`r round(pD,3)`-`r round(pL,3)`=$$\n  \n## Hypothesis set\nOur research hypothesis of interest is that using Desipramine will have a lower relapse proportion than patients who receive Lithium.  Our hypothesis set is:\n$$NH: p_D=p_L$$\n$$AH: pD>p_L$$  \n\nEquivalently we can rewrite the above hypothesis set as\n\n$$NH: p_D-p_L=0$$\n$$NH: pD-p_L >0$$  \n\n## Creating the randomization distribution\nBecause in experiments treatments are randomized to experimental subjects our reference distribution should be created in the same way.  We can do this by using the R-function $sample.int$$.  WE will show how to do this below for a single randomization sample.  \n\n```{r Q5.2,echo=TRUE}\n#\n###########################################################\n# We need to change the strings to numeric o's and 1's so #\n# we can use the mean function to compute proportions.    #\n###########################################################\n#\ny <- ifelse(CT$Relapse[1:48]==\"yes\",1, 0 )\n#\n#\n###########################################################\n# We create an index to assign treatments to the random   #\n# Groups D and L.                                         #\n###########################################################\n#\nAll <- 1:48\n#\n#\n###########################################################\n# We ranomly assign 24 of the values in y to group D.     #\n###########################################################\n#\nD <- sample.int( 48, 24, replace=FALSE)\nD\ny[D]\n#\n#\n###########################################################\n# We assign any objects not assigned to group D to group   #\n# group L.                                                #\n###########################################################\nL <- All[-D]\nL\ny[L]\n#\n#\n##########################################################\n# We compute the difference between the completely       #\n# randomized groups.                                     #\n##########################################################\n#\ndif <- mean(y[D]) - mean( y[L])\ndif\n\n```\nIn practice we need to do this a large number of times.  The code below will create randomization distribution with 20,000 replcations using the drug data.  \n\n```{r Q5.4,echo=TRUE}\nreps <- 20000\nrd   <- rep( NA, reps)\n\noutcome <- ifelse(CT$Relapse[1:48]==\"yes\", 1, 0 )\ntrials   <- 1:48\n\nfor( i in 1:reps){\n    D <- sample.int( 48, 24, replace=FALSE )\n    L <- trials[-D]\n    rd[i]= mean( y[D] - y[L])\n}\n\n```\n\nThe mean of the randomization should be approximately equal to zero.  Its value is `r round( mean( rd), 3)`.  This value is close to zero.\n\nWe plot the randomization distribution below.  \n\n```{r Q5.5,echo=TRUE}\nrequire( ggplot2 )\n\nggplot(  data.frame(rd),\n         aes(x=rd)) +\n    geom_histogram( binwidth=0.10,\n                    color=\"blue\",\n                    fill=\"yellow\")\n```\n\n## Computing the p-value\nWE have a lower tail test so the p-value is computed for all the randomization values less that the variable $pDif$.  \n\n```{r Q5.6,echo=TRUE}\n\npValue <- round( length( rd[rd >= pDif] ) / reps, 4 )\n\n```\n  \n$$p-value=`r pValue`$$\n\n## Statistical conclusion\nbecause the p-value of `r pValue` is much smaller than 0.0500 we conclude that the bull hypothesis is incorrect.  \n\n## Clinical conclusion \nThere is very strong sample evidence to conclude that Desipramine reduces relapses more than Lithium.\n\n# Using a confidence interval to test a hypotheis\nSuppose a craft brewer brews a beer called Winter Warmer.  The beer should have an alcholoic content of 11%.  A random sample of size 15 is drawn from 10 random retail outlets and the alcololic content by volume, $ABV$ is measured.  \n\nThe sample data is given below.\n\n```{r Bewer,echo=FALSE}\nrm( list=ls())\nset.seed( 31853211 )\nABV <- round( rnorm( 10, 11.5, 0.3) ,1 )\nABV\n  \n```\nTest the null hypothesis at the 5% kevel of significance by using a 95% confidence interval.  Use the bootstrap to perform the computations.\n\n```{r echo=TRUE}\nrequire( simpleboot )\n\nreps <- 10000\n\nbootOut <- one.boot( ABV,\n                      reps )\nbsd <- bootOut$t\n\n\ncat( \"Bootstrap diagnostics\" )\n```\n\n\n\n\n## The null and the alternative hypotheses \nBecause we do not apriori know if the ABV is higher or lower we use a two-tailed hypothesis test.  \n\n$$NH: \\mu=11$$\n$$AH: \\mu \\ne 11$$\n\n",
    "created" : 1445972695285.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1777347420",
    "id" : "843F9BFC",
    "lastKnownWriteTime" : 1445994974,
    "path" : "C:/Users/Craig/BSTAT3322/Examples/HypothesisTesting/HypothesisTesting.Rmd",
    "project_path" : "HypothesisTesting.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_markdown"
}